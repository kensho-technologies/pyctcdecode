{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use pyctcdecode when working with a NeMo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install NeMo\n",
    "!pip install \"nemo-toolkit[asr]==1.3.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-01 10:20:31--  https://dldata-public.s3.us-east-2.amazonaws.com/1919-142785-0028.wav\n",
      "Resolving dldata-public.s3.us-east-2.amazonaws.com (dldata-public.s3.us-east-2.amazonaws.com)... 52.219.88.16\n",
      "Connecting to dldata-public.s3.us-east-2.amazonaws.com (dldata-public.s3.us-east-2.amazonaws.com)|52.219.88.16|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 165164 (161K) [audio/wav]\n",
      "Saving to: ‘1919-142785-0028.wav’\n",
      "\n",
      "1919-142785-0028.wa 100%[===================>] 161.29K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2021-10-01 10:20:31 (1.94 MB/s) - ‘1919-142785-0028.wav’ saved [165164/165164]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get a single audio file\n",
    "!wget https://dldata-public.s3.us-east-2.amazonaws.com/1919-142785-0028.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained NeMo model\n",
    "import nemo.collections.asr as nemo_asr\n",
    "# we could choose for example a BPE encoded conformer-ctc model\n",
    "# asr_model = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(model_name='stt_en_conformer_ctc_small')\n",
    "# let's take a standard quartznet model though to start\n",
    "asr_model = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name='QuartzNet15x5Base-En')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9ee9e92297439f81dded72d3590a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# transcribe audio to logits\n",
    "logits = asr_model.transcribe([\"1919-142785-0028.wav\"], logprobs=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the alphabet of our model defining the labels for the logit matrix we just calculated\n",
    "asr_model.decoder.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boil them before they are put into the soup or other dish they may be intended for'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyctcdecode import build_ctcdecoder\n",
    "\n",
    "# build the decoder and decode the logits\n",
    "decoder = build_ctcdecoder(asr_model.decoder.vocabulary)\n",
    "decoder.decode(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librispeech experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real use of a decoder however comes from the ability to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: some of this code is borrowed from the official NeMo tutorial \n",
    "#     https://github.com/NVIDIA/NeMo/blob/main/tutorials/asr/Offline_ASR.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pretrained knelm model for librispeech\n",
    "# NOTE: since out nemo vocabulary is all lowercased, we need to convert all librispeech data as well\n",
    "import gzip\n",
    "import os, shutil, wget\n",
    "\n",
    "lm_gzip_path = '3-gram.pruned.1e-7.arpa.gz'\n",
    "if not os.path.exists(lm_gzip_path):\n",
    "    print('Downloading pruned 3-gram model.')\n",
    "    lm_url = 'http://www.openslr.org/resources/11/3-gram.pruned.1e-7.arpa.gz'\n",
    "    lm_gzip_path = wget.download(lm_url)\n",
    "    print('Downloaded the 3-gram language model.')\n",
    "else:\n",
    "    print('Pruned .arpa.gz already exists.')\n",
    "\n",
    "uppercase_lm_path = '3-gram.pruned.1e-7.arpa'\n",
    "if not os.path.exists(uppercase_lm_path):\n",
    "    with gzip.open(lm_gzip_path, 'rb') as f_zipped:\n",
    "        with open(uppercase_lm_path, 'wb') as f_unzipped:\n",
    "            shutil.copyfileobj(f_zipped, f_unzipped)\n",
    "    print('Unzipped the 3-gram language model.')\n",
    "else:\n",
    "    print('Unzipped .arpa already exists.')\n",
    "\n",
    "lm_path = 'lowercase_3-gram.pruned.1e-7.arpa'\n",
    "if not os.path.exists(lm_path):\n",
    "    with open(uppercase_lm_path, 'r') as f_upper:\n",
    "        with open(lm_path, 'w') as f_lower:\n",
    "            for line in f_upper:\n",
    "                f_lower.write(line.lower())\n",
    "print('Converted language model file to lowercase.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-27 12:26:03--  http://www.openslr.org/resources/11/librispeech-vocab.txt\n",
      "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
      "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1737588 (1.7M) [text/plain]\n",
      "Saving to: ‘librispeech-vocab.txt’\n",
      "\n",
      "librispeech-vocab.t 100%[===================>]   1.66M  1.07MB/s    in 1.6s    \n",
      "\n",
      "2021-04-27 12:26:05 (1.07 MB/s) - ‘librispeech-vocab.txt’ saved [1737588/1737588]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download unigram vocab\n",
    "!wget http://www.openslr.org/resources/11/librispeech-vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load unigram list\n",
    "with open(\"librispeech-vocab.txt\") as f:\n",
    "    unigram_list = [t.lower() for t in f.read().strip().split(\"\\n\")]\n",
    "    \n",
    "# load kenlm Model\n",
    "import kenlm\n",
    "kenlm_model = kenlm.Model('lowercase_3-gram.pruned.1e-7.arpa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boil them before they are put into the soup or other dish they may be intended for'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = build_ctcdecoder(\n",
    "    asr_model.decoder.vocabulary,\n",
    "    kenlm_model,\n",
    "    unigram_list,\n",
    ")\n",
    "decoder.decode(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on librispeech dev-other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download librispeech dev-other corpus, using one of the great existing scripts, for example:\n",
    "#     https://github.com/NVIDIA/NeMo/blob/main/scripts/dataset_processing/get_librispeech_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load manifest that holds meta information on all files in dev_other\n",
    "import pandas as pd\n",
    "dev_other_df = pd.read_json(\"/my_dir/dev_other.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode all logits (this may take a while)\n",
    "logits_list = [\n",
    "    a.cpu().detach().numpy() \n",
    "    for a in asr_model.transcribe(dev_other_df[\"audio_filepath\"].tolist(), logprobs=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = build_ctcdecoder(\n",
    "    asr_model.decoder.vocabulary,\n",
    "    kenlm_model,\n",
    "    unigram_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "with multiprocessing.get_context(\"fork\").Pool() as pool:\n",
    "    pred_list = decoder.decode_batch(pool, logits_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07708590580349269"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nemo.collections.asr.metrics.wer import word_error_rate\n",
    "word_error_rate(dev_other_df[\"text\"].tolist(), pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's compare this to greedy decoding\n",
    "def _greedy_decode(logits):\n",
    "    \"\"\"Decode argmax of logits and squash in CTC fashion.\"\"\"\n",
    "    label_dict = {n: c for n, c in enumerate(labels)}\n",
    "    prev_c = None\n",
    "    out = []\n",
    "    for n in logits.argmax(axis=1):\n",
    "        c = label_dict.get(n, \"\")  # if not in labels, then assume it's ctc blank char\n",
    "        if c != prev_c:\n",
    "            out.append(c)\n",
    "        prev_c = c\n",
    "    return \"\".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10084215497225611"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_error_rate(dev_other_df[\"text\"].tolist(), [_greedy_decode(l) for l in logits_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we did better by using a language model, but we can improve this further by tuning the decoder parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gridsearch optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.076822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.076937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.077032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.077083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.077113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha  beta       wer\n",
       "4    0.7   3.0  0.076822\n",
       "0    0.6   2.0  0.076937\n",
       "1    0.6   3.0  0.077032\n",
       "3    0.7   2.0  0.077083\n",
       "7    0.8   3.0  0.077113"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_grid = []\n",
    "for a in [0.6, 0.7, 0.8]:\n",
    "    for b in [2.0, 3.0, 4.0]:\n",
    "        decoder.reset_params(alpha=a, beta=b)\n",
    "        with multiprocessing.get_context(\"fork\").Pool(15) as pool:\n",
    "            # use lower beam-with here for fast testing\n",
    "            lm_preds =  decoder.decode_batch(pool, logits_list, beam_width=50)\n",
    "        wer_val = word_error_rate(dev_other_df[\"text\"].tolist(), lm_preds)\n",
    "        data_grid.append((a, b, wer_val))\n",
    "pd.DataFrame(data_grid, columns=[\"alpha\", \"beta\", \"wer\"]).sort_values(by=\"wer\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# advanced parameters to tune:\n",
    "#     beam_width: how many beams to keep after each step\n",
    "#     beam_prune_logp: beams that are much worse than best beam will be pruned\n",
    "#     token_min_logp: tokens below this logp are skipped unless they are argmax of frame\n",
    "#     prune_logp: beams that are much worse than best beam will be pruned\n",
    "#     unk_score_offset: score decrease for token if oov\n",
    "#     lm_score_boundary: whether to have kenlm respect boundaries when scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
